{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyCBC Inference 2: Analyzing a gravitational wave\n",
    "### Collin Capano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we show how to set up a run for a gravitation wave, in this case, GW150914."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "We will need the most recent version of pycbc installed for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already satisfied: pycbc in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/PyCBC-ee90d2-py2.7-macosx-10.13-x86_64.egg (ee90d2)\n",
      "Requirement already satisfied: lalsuite in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (6.53)\n",
      "Collecting ligo-common\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/9c/1fbe176feea9abad5c0f3fa090dcffccf44bbcba0f0c754b03d8fea1a36e/ligo_common-1.0.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy<1.15.3,>=1.13.0 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (1.15.2)\n",
      "Requirement already satisfied: Mako>=1.0.1 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (1.0.8)\n",
      "Requirement already satisfied: cython in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (0.29.6)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (4.4.0)\n",
      "Requirement already satisfied: scipy>=0.16.0 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (1.2.1)\n",
      "Requirement already satisfied: matplotlib>=1.5.1 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (2.2.4)\n",
      "Requirement already satisfied: pillow in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (5.4.1)\n",
      "Requirement already satisfied: h5py>=2.5 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (2.9.0)\n",
      "Requirement already satisfied: jinja2 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (2.10)\n",
      "Requirement already satisfied: mpld3>=0.3 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (0.3)\n",
      "Requirement already satisfied: lscsoft-glue>=1.59.3 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (2.0.0)\n",
      "Requirement already satisfied: emcee==2.2.1 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (2.2.1)\n",
      "Requirement already satisfied: requests>=1.2.1 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (2.21.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (4.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (1.12.0)\n",
      "Requirement already satisfied: ligo-segments in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (1.2.0)\n",
      "Requirement already satisfied: astropy<3.0.0,>=2.0.3 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (2.0.12)\n",
      "Requirement already satisfied: weave>=0.16.0 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pycbc) (0.17.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from lalsuite) (2.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from Mako>=1.0.1->pycbc) (1.0)\n",
      "Requirement already satisfied: subprocess32 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from matplotlib>=1.5.1->pycbc) (3.5.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from matplotlib>=1.5.1->pycbc) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from matplotlib>=1.5.1->pycbc) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from matplotlib>=1.5.1->pycbc) (2.3.1)\n",
      "Requirement already satisfied: backports.functools-lru-cache in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from matplotlib>=1.5.1->pycbc) (1.5)\n",
      "Requirement already satisfied: pytz in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from matplotlib>=1.5.1->pycbc) (2018.9)\n",
      "Requirement already satisfied: pyOpenSSL in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from lscsoft-glue>=1.59.3->pycbc) (16.2.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from requests>=1.2.1->pycbc) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from requests>=1.2.1->pycbc) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from requests>=1.2.1->pycbc) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from requests>=1.2.1->pycbc) (1.24.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from beautifulsoup4>=4.6.0->pycbc) (1.9)\n",
      "Requirement already satisfied: pytest<3.7,>=2.8 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from astropy<3.0.0,>=2.0.3->pycbc) (3.6.4)\n",
      "Requirement already satisfied: setuptools in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.1->pycbc) (40.8.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pyOpenSSL->lscsoft-glue>=1.59.3->pycbc) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pytest<3.7,>=2.8->astropy<3.0.0,>=2.0.3->pycbc) (19.1.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pytest<3.7,>=2.8->astropy<3.0.0,>=2.0.3->pycbc) (0.7.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pytest<3.7,>=2.8->astropy<3.0.0,>=2.0.3->pycbc) (5.0.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pytest<3.7,>=2.8->astropy<3.0.0,>=2.0.3->pycbc) (1.3.0)\n",
      "Requirement already satisfied: funcsigs; python_version < \"3.0\" in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pytest<3.7,>=2.8->astropy<3.0.0,>=2.0.3->pycbc) (1.0.2)\n",
      "Requirement already satisfied: py>=1.5.0 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from pytest<3.7,>=2.8->astropy<3.0.0,>=2.0.3->pycbc) (1.8.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from cryptography>=1.3.4->pyOpenSSL->lscsoft-glue>=1.59.3->pycbc) (1.12.2)\n",
      "Requirement already satisfied: ipaddress; python_version < \"3\" in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from cryptography>=1.3.4->pyOpenSSL->lscsoft-glue>=1.59.3->pycbc) (1.0.22)\n",
      "Requirement already satisfied: enum34; python_version < \"3\" in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from cryptography>=1.3.4->pyOpenSSL->lscsoft-glue>=1.59.3->pycbc) (1.1.6)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from cryptography>=1.3.4->pyOpenSSL->lscsoft-glue>=1.59.3->pycbc) (0.24.0)\n",
      "Requirement already satisfied: pycparser in /Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=1.3.4->pyOpenSSL->lscsoft-glue>=1.59.3->pycbc) (2.19)\n",
      "Installing collected packages: ligo-common\n",
      "Successfully installed ligo-common-1.0.3\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pycbc lalsuite ligo-common --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBH example\n",
    "\n",
    "We will use the provided example configuration file [bbh_example.ini](bbh_example.ini). This is the configuration file you would need to analyze signals like GW150914.\n",
    "\n",
    "In the following sections, we look at the various sections of the configuration file in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "The model we will use is set by the `[model]` section. By setting the `name = gaussian_noise`, we tell `pycbc_inference` that we want to use the [GaussianNoise](https://pycbc.org/pycbc/latest/html/pycbc.inference.models.html#pycbc.inference.models.gaussian_noise.GaussianNoise) model. This means that we will be analyzing data $d$ from one or more detectors, which is sampled at some constant sample rate $1/\\Delta t$ for a period of time $T$, yielding $N = T/\\Delta t$ samples (more on how to load data below).\n",
    "\n",
    "This model assumes that the data consists of stationary Gaussian noise plus a signal $h$. The signal is modeled by a waveform model, which depends on several parameters. Which model to use is determined by the `approximant` parameter, which is set in the `static_params` section (see below).\n",
    "\n",
    "When this model is given a set of parameter values $\\vec{\\vartheta}$, it generates a frequency-domain waveform $\\tilde{h}(\\vec{\\vartheta})$ using the waveform model. It then calculates the log likelihood:\n",
    "\\begin{equation}\n",
    "\\log p(d|\\vec{\\vartheta}, h) =  -\\frac{1}{2} \\sum_i \\left< h_i(\\vec{\\vartheta}) - d_i,\\, h_i(\\vec{\\vartheta}) - d_i \\right>,\n",
    "\\end{equation}\n",
    "where the sum is over the number of detectors. The inner product is given by:\n",
    "\\begin{equation}\n",
    "\\left<a_i, \\, b_i\\right> = 4 \\Re \\sum_{k=k_0}^{N/2} \\frac{\\tilde{a}_i^{*}(k \\Delta f) \\tilde{b}_i(k \\Delta f)}{S^{(i)}_n(k\\Delta f)} \\Delta f.\n",
    "\\end{equation}\n",
    "Here, $S_n^{(i)}$ is the power spectral density of the noise in the $i$th detector and $\\Delta f = 1/T$ is the frequency resolution. This is the discrete form of the matched filter (see Matt Pitkin's talk).\n",
    "\n",
    "As we see, the model requires a lower frequency cutoff for the inner product $f_0 = k_0 \\Delta f$. This is set for each detector by setting the `{detector}-low-frequency-cutoff` option where `{detector}` is the detector name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The variable and static params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the Normal 2D example, we see that there is a `[variable_params]` section. This lists the names of all of the parameters we will be varying in the run. Now we see that there is also a `[static_params]` section. These are parameters that will be kept fixed throughout the run. In this example we have:\n",
    " * `approximant = IMRPhenomPv2`: this means that the waveform model we use will be IMRPhenomPv2\n",
    " * `f_lower = 20`: this sets the starting frequency for the waveform generation to 20Hz. *This is separate from the low frequency cutoff of the inner product, which is set in the `[model]` section.*\n",
    " * `f_ref = 20`: the \"reference\" frequency of the waveform.\n",
    "\n",
    "The `approximant` argument determines what type of waveform we will be generating. Since it is set to `IMRPhenomPv2`, we will be generating a CBC waveform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the prior\n",
    "\n",
    "**Every parameter listed in the `[variable_params]` section must have a prior specified in the file.** This is done by adding sections named `[prior-{params}]` to the file, where `{param}` is the name of the parameter that the section sets a prior for; e.g., `[prior-mass1]`. A section may provide a distribution for multiple parameters. In that case, all of the parameters must be listed in the header as a `+` separated list. For example, `[prior-ra+dec]`. The order that the parameters are provided does not matter.\n",
    "\n",
    "Each prior section must also have a `name` set. This specifies the name of the distribution to use for that parameter. Distributions are defined in PyCBC's [distributions package](https://pycbc.org/pycbc/latest/html/pycbc.distributions.html); several are available for use. For the complete list, see the table [here](https://pycbc.org/pycbc/latest/html/inference.html#configuring-the-prior).\n",
    "\n",
    "The rest of the settings in the `[prior]` sections depend on the distribution being used. For example, the `uniform` distribution requires minimum and maximum bounds to be provided for each parameter:\n",
    "```\n",
    "[prior-mass1]\n",
    "name = uniform\n",
    "min-mass1 = 10.\n",
    "max-mass1 = 80.\n",
    "```\n",
    "Some distributions require no options, since they are predefined in the code. For example, the `uniform_sky` distribution provides the appropriate distributions for right ascension and declination, which it expects to be called `ra` and `dec`, respectively. This is why that section is simply:\n",
    "```\n",
    "[prior-ra+dec]\n",
    "name = uniform_sky\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    " * The configuration file is missing a prior for the coalescene time `tc`. We know that the coalescence time of GW150914 is approximately 1126259462.42 (GPS seconds). Set a uniform prior on `tc` equal to this time $\\pm$ 0.1 s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sampler\n",
    "\n",
    "Here we are using the `emcee_pt` sampler. This is a parallel tempered sampler, so it requires a number of temperatures to be set. Note a few other differences from the analytic example here:\n",
    "  * The `burn-in-test` is set to `nacl & max_posterior`.\n",
    "  * Instead of an `niterations` option, we have `effective-nsamples = 1000`.\n",
    "  * A checkpoint interval is set: `checkpoint-interval = 2000`\n",
    "  * There is a `max-samples-per-chain` option.\n",
    "\n",
    "These are all options specific to MCMC samplers like `emcee_pt`. Details:\n",
    "\n",
    "#### The burn in option\n",
    "Multiple burn in tests may be combined using standard boolean operators like `&` and `|`. In this example, we will consider the sampler to be burned in when it has passed the `nacl` test *and* the `max_posterior` test. This means:\n",
    "\n",
    " * `nacl`: The second half of the chain must be longer than 5 times the ACL. If so, the samlper is considered burned-in at the halfway point.\n",
    " * `max_posterior`: All of the walkers must find a point that has a log posterior greater than `maxP - ndim/2`, where `maxP` is the maximum posterior value found over all the walkers and `ndim` is the number of variable parameters. The first iteration for which all the walkers pass this test is the burn in iteration.\n",
    " \n",
    "By doing `&`, we take the larger iteration of these two tests. This combination of tests has worked well for `emcee_pt`.\n",
    "\n",
    "#### Checkpointing\n",
    "When a `checkpoint-interval` is set, `pycbc_inference` will dump the results to a checkpoint file after every `checkpoint-interval` iterations. The checkpoint file has the same name as the output, but with `.checkpoint` added on to it. \n",
    "\n",
    "While ``pycbc_inference`` is running it will create a checkpoint file which\n",
    "is named ``{output-file}.checkpoint``, where ``{output-file}`` was the name\n",
    "of the file you specified with the ``--output-file`` command. If a `checkpoint-interval` is set, `pycbc_inference` will checkpoint after the given number of iterations. For `emcee_pt`, this means that it will dump the current samples to this file; when finished, the file is\n",
    "renamed to ``{output-file}``.\n",
    "\n",
    "A ``{output-file}.bkup`` is also created, which is a copy of the checkpoint file. This is kept in case the checkpoint file gets corrupted during writing. The ``.bkup`` file is deleted at the end of the run, unless ``--save-backup`` is turned on.\n",
    "\n",
    "If `pycbc_inference` is terminated while running (either by error, or by a system interrupt), the checkpoint and bkup files remain. When `pycbc_inference` is restarted, it will check for those files. If they are found, it will resume from where it last left off.\n",
    "\n",
    "#### Termination condition\n",
    "By setting `effective-nsamples` we tell the `pycbc_inference` until it has an effective number of samples greater than or equal to the specified value. Effective samples are the number of independent samples of the posterior we have. This is given by number of samples that remain after burn-in and thinned by the autocorelation time.\n",
    "\n",
    "The number of effective samples are counted at each checkpoint. For this reason, a checkpoint-interval must be provided if `effective-nsamples` is set.\n",
    "\n",
    "#### Max samples per chain\n",
    "If `max-samples-per-chain` is provided, `pycbc_inference` will ensure that no more than the given number of samples per chain are stored in the output file. Samples will be thinned on disk and in memory when a checkpoint happens to ensure this. This is important for keeping file size down. Without it, a GW run with `1000` walkers and `4` temps can result in a file that is over 100GB, since every sample will be saved. With `max-samples-per-chain = 1000`, the maximum file size is capped to ~1GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samping and waveform transforms\n",
    "You'll note a `waveform_transforms` and `sampling_transforms` sections. Those are described in more detail in the next tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data settings\n",
    "\n",
    "Options for loading the gravitational wave data are set on the command line. See [run_bbh_example.sh](run_bbh_example.sh) for details.\n",
    "\n",
    "### Challenge:\n",
    " * The data that will be analyzed is set by the `--gps-start-time` and `--gps-end-time` options. What will these be set to by the script? How much time is analyzed?\n",
    " * The longest waveform admitted by the prior is ~6s long. So why is the analyzed time longer than 6 seconds? (Hint: Recall FFT wrap around.)\n",
    " \n",
    "*Note: in a future release, data options will be moved from the command line and into the config file.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can run, we need to download frame files from [GWOSC](https://www.gw-openscience.org/about/). These contain the LIGO data that we will analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-13 11:08:54--  https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf\n",
      "Resolving www.gw-openscience.org (www.gw-openscience.org)... 131.215.125.179\n",
      "Connecting to www.gw-openscience.org (www.gw-openscience.org)|131.215.125.179|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /catalog/GWTC-1-confident/data/GW150914/H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf/ [following]\n",
      "--2019-05-13 11:08:55--  https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf/\n",
      "Reusing existing connection to www.gw-openscience.org:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 130069555 (124M) [application/x-gwf]\n",
      "Saving to: ‘H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf’\n",
      "\n",
      "H-H1_GWOSC_4KHZ_R1- 100%[===================>] 124.04M  6.61MB/s    in 20s     \n",
      "\n",
      "2019-05-13 11:09:15 (6.27 MB/s) - ‘H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf’ saved [130069555/130069555]\n",
      "\n",
      "--2019-05-13 11:09:16--  https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf\n",
      "Resolving www.gw-openscience.org (www.gw-openscience.org)... 131.215.125.179\n",
      "Connecting to www.gw-openscience.org (www.gw-openscience.org)|131.215.125.179|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /catalog/GWTC-1-confident/data/GW150914/L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf/ [following]\n",
      "--2019-05-13 11:09:16--  https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf/\n",
      "Reusing existing connection to www.gw-openscience.org:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 125704995 (120M) [application/x-gwf]\n",
      "Saving to: ‘L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf’\n",
      "\n",
      "L-L1_GWOSC_4KHZ_R1- 100%[===================>] 119.88M  6.76MB/s    in 19s     \n",
      "\n",
      "2019-05-13 11:09:36 (6.27 MB/s) - ‘L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf’ saved [125704995/125704995]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf'):\n",
    "    !wget https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf\n",
    "if not os.path.exists('L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf'):\n",
    "    !wget https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this example, we will just run the bash script. Running this example to completion will take several hours. Instead, we'll just run for a couple of checkpoints, kill it, then start it again to see how checkpointing works.\n",
    "\n",
    "First, do the following:\n",
    " * Set the checkpoint interval in the config file to 4.\n",
    "\n",
    "Now run the script. Watch the output. After it checkpoints (it will say \"Running sampler for 4 to 8 iterations\"), interrupt the kernel by hitting the stop button above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 11:13:38,887 Using seed 39392\n",
      "2019-05-13 11:13:38,887 Running with CPU support: 1 threads\n",
      "2019-05-13 11:13:39,171 Reading Frames\n",
      "2019-05-13 11:13:48,375 Highpass Filtering\n",
      "2019-05-13 11:13:48,383 Converting to float64\n",
      "2019-05-13 11:13:48,383 Resampling data\n",
      "2019-05-13 11:13:48,412 Highpass Filtering\n",
      "2019-05-13 11:13:48,419 Remove Padding\n",
      "2019-05-13 11:13:48,422 Reading Frames\n",
      "2019-05-13 11:13:57,713 Highpass Filtering\n",
      "2019-05-13 11:13:57,719 Converting to float64\n",
      "2019-05-13 11:13:57,720 Resampling data\n",
      "2019-05-13 11:13:57,734 Highpass Filtering\n",
      "2019-05-13 11:13:57,738 Remove Padding\n",
      "2019-05-13 11:13:57,738 Will generate a different time series for PSD estimation\n",
      "2019-05-13 11:13:57,738 Reading Frames\n",
      "2019-05-13 11:14:06,566 Highpass Filtering\n",
      "2019-05-13 11:14:06,779 Converting to float64\n",
      "2019-05-13 11:14:06,789 Resampling data\n",
      "2019-05-13 11:14:07,533 Highpass Filtering\n",
      "2019-05-13 11:14:07,655 Remove Padding\n",
      "2019-05-13 11:14:07,656 Reading Frames\n",
      "2019-05-13 11:14:16,713 Highpass Filtering\n",
      "2019-05-13 11:14:16,914 Converting to float64\n",
      "2019-05-13 11:14:16,924 Resampling data\n",
      "2019-05-13 11:14:17,606 Highpass Filtering\n",
      "2019-05-13 11:14:17,729 Remove Padding\n",
      "2019-05-13 11:14:17,729 Applying gates to PSD data\n",
      "2019-05-13 11:14:18,345 Reading configuration file\n",
      "2019-05-13 11:14:18,347 Setting up model\n",
      "2019-05-13 11:14:18,347 Setting up priors for each parameter\n",
      "2019-05-13 11:14:18,351 Sampling in q, mchirp in place of mass1, mass2\n",
      "2019-05-13 11:14:18,351 Loading waveform transforms\n",
      "2019-05-13 11:14:19,688 Setting up sampler\n",
      "2019-05-13 11:14:19,703 Setting max samples per chain to 1000\n",
      "2019-05-13 11:14:19,705 Looking for checkpoint file\n",
      "2019-05-13 11:14:19,729 Checkpoint not found or not valid\n",
      "2019-05-13 11:14:19,730 Creating file bbh_results.hdf.checkpoint\n",
      "2019-05-13 11:14:21,751 Running sampler for 0 to 4 iterations\n",
      "2019-05-13 11:15:18,700 Writing samples to bbh_results.hdf.checkpoint with thin interval 1\n",
      "2019-05-13 11:15:18,740 Writing samples to bbh_results.hdf.bkup with thin interval 1\n",
      "2019-05-13 11:15:18,775 Updating burn in\n",
      "2019-05-13 11:15:18,818 Is burned in: False\n",
      "2019-05-13 11:15:18,819 Computing acls\n",
      "2019-05-13 11:15:18,853 ACT: inf\n",
      "2019-05-13 11:15:18,884 Validating checkpoint and backup files\n",
      "2019-05-13 11:15:18,924 Clearing samples from memory\n",
      "2019-05-13 11:15:18,924 Have 0 effective samples post burn in\n",
      "2019-05-13 11:15:18,924 Running sampler for 4 to 8 iterations\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/bin/pycbc_inference\", line 4, in <module>\n",
      "    __import__('pkg_resources').run_script('PyCBC===ee90d2', 'pycbc_inference')\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 666, in run_script\n",
      "    self.require(requires)[0].run_script(script_name, ns)\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 1446, in run_script\n",
      "    exec(code, namespace, namespace)\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/PyCBC-ee90d2-py2.7-macosx-10.13-x86_64.egg/EGG-INFO/scripts/pycbc_inference\", line 210, in <module>\n",
      "    sampler.run()\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/PyCBC-ee90d2-py2.7-macosx-10.13-x86_64.egg/pycbc/inference/sampler/base_mcmc.py\", line 492, in run\n",
      "    self.run_mcmc(iterinterval)\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/PyCBC-ee90d2-py2.7-macosx-10.13-x86_64.egg/pycbc/inference/sampler/emcee_pt.py\", line 241, in run_mcmc\n",
      "    res = self._sampler.run_mcmc(pos, niterations)\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/emcee/sampler.py\", line 172, in run_mcmc\n",
      "    **kwargs):\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/emcee/ptsampler.py\", line 259, in sample\n",
      "    results = list(self.pool.map(fn, p.reshape((-1, self.dim))))\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/PyCBC-ee90d2-py2.7-macosx-10.13-x86_64.egg/pycbc/pool.py\", line 112, in map\n",
      "    raise KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash run_bbh_example.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run `ls` to see the files in the diretory. You should see a `bbh_results.hdf.checkpoint` and `bbh_results.hdf.bkup`. These are your checkpoint and backup files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf bbh_results.hdf.bkup\r\n",
      "IntroToPyCBCInference2.ipynb           bbh_results.hdf.checkpoint\r\n",
      "L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf run_bbh_example.sh\r\n",
      "bbh_example.ini\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script again. Watch the messages. You should see it say that it is starting from iteration 4. Stop it after it has gotten to another checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 11:16:03,158 Using seed 39392\n",
      "2019-05-13 11:16:03,159 Running with CPU support: 1 threads\n",
      "2019-05-13 11:16:03,442 Reading Frames\n",
      "2019-05-13 11:16:12,527 Highpass Filtering\n",
      "2019-05-13 11:16:12,534 Converting to float64\n",
      "2019-05-13 11:16:12,534 Resampling data\n",
      "2019-05-13 11:16:12,558 Highpass Filtering\n",
      "2019-05-13 11:16:12,562 Remove Padding\n",
      "2019-05-13 11:16:12,563 Reading Frames\n",
      "2019-05-13 11:16:22,663 Highpass Filtering\n",
      "2019-05-13 11:16:22,669 Converting to float64\n",
      "2019-05-13 11:16:22,669 Resampling data\n",
      "2019-05-13 11:16:22,681 Highpass Filtering\n",
      "2019-05-13 11:16:22,684 Remove Padding\n",
      "2019-05-13 11:16:22,684 Will generate a different time series for PSD estimation\n",
      "2019-05-13 11:16:22,685 Reading Frames\n",
      "2019-05-13 11:16:31,721 Highpass Filtering\n",
      "2019-05-13 11:16:31,940 Converting to float64\n",
      "2019-05-13 11:16:31,950 Resampling data\n",
      "2019-05-13 11:16:32,793 Highpass Filtering\n",
      "2019-05-13 11:16:32,913 Remove Padding\n",
      "2019-05-13 11:16:32,914 Reading Frames\n",
      "2019-05-13 11:16:42,449 Highpass Filtering\n",
      "2019-05-13 11:16:42,669 Converting to float64\n",
      "2019-05-13 11:16:42,679 Resampling data\n",
      "2019-05-13 11:16:43,452 Highpass Filtering\n",
      "2019-05-13 11:16:43,563 Remove Padding\n",
      "2019-05-13 11:16:43,563 Applying gates to PSD data\n",
      "2019-05-13 11:16:44,234 Reading configuration file\n",
      "2019-05-13 11:16:44,238 Setting up model\n",
      "2019-05-13 11:16:44,239 Setting up priors for each parameter\n",
      "2019-05-13 11:16:44,243 Sampling in q, mchirp in place of mass1, mass2\n",
      "2019-05-13 11:16:44,243 Loading waveform transforms\n",
      "2019-05-13 11:16:45,568 Setting up sampler\n",
      "2019-05-13 11:16:45,618 Setting max samples per chain to 1000\n",
      "2019-05-13 11:16:45,622 Looking for checkpoint file\n",
      "2019-05-13 11:16:45,678 Initial positions taken from last iteration in bbh_results.hdf.checkpoint\n",
      "2019-05-13 11:16:45,737 Running sampler for 4 to 8 iterations\n",
      "2019-05-13 11:17:32,413 Writing samples to bbh_results.hdf.checkpoint with thin interval 1\n",
      "2019-05-13 11:17:32,461 Writing samples to bbh_results.hdf.bkup with thin interval 1\n",
      "2019-05-13 11:17:32,550 Updating burn in\n",
      "2019-05-13 11:17:32,620 Is burned in: False\n",
      "2019-05-13 11:17:32,621 Computing acls\n",
      "2019-05-13 11:17:32,678 ACT: inf\n",
      "2019-05-13 11:17:32,721 Validating checkpoint and backup files\n",
      "2019-05-13 11:17:32,788 Clearing samples from memory\n",
      "2019-05-13 11:17:32,789 Have 0 effective samples post burn in\n",
      "2019-05-13 11:17:32,789 Running sampler for 8 to 12 iterations\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/bin/pycbc_inference\", line 4, in <module>\n",
      "    __import__('pkg_resources').run_script('PyCBC===ee90d2', 'pycbc_inference')\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 666, in run_script\n",
      "    self.require(requires)[0].run_script(script_name, ns)\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 1446, in run_script\n",
      "    exec(code, namespace, namespace)\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/PyCBC-ee90d2-py2.7-macosx-10.13-x86_64.egg/EGG-INFO/scripts/pycbc_inference\", line 210, in <module>\n",
      "    sampler.run()\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/PyCBC-ee90d2-py2.7-macosx-10.13-x86_64.egg/pycbc/inference/sampler/base_mcmc.py\", line 492, in run\n",
      "    self.run_mcmc(iterinterval)\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/PyCBC-ee90d2-py2.7-macosx-10.13-x86_64.egg/pycbc/inference/sampler/emcee_pt.py\", line 241, in run_mcmc\n",
      "    res = self._sampler.run_mcmc(pos, niterations)\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/emcee/sampler.py\", line 172, in run_mcmc\n",
      "    **kwargs):\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/emcee/ptsampler.py\", line 259, in sample\n",
      "    results = list(self.pool.map(fn, p.reshape((-1, self.dim))))\n",
      "  File \"/Users/cdcapano/.virtualenvs/pycbc-master/lib/python2.7/site-packages/PyCBC-ee90d2-py2.7-macosx-10.13-x86_64.egg/pycbc/pool.py\", line 112, in map\n",
      "    raise KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash run_bbh_example.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace `effective-nsamples` by `niterations` in the config file to get this to complete now. Remove or comment out the `effective-nsamples` option, and replace it with: `niterations = 12`. Now re-run. You should see `pycbc_inference` start up from the last checkpoint, but stop as soon as it gets to 12 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 11:18:20,051 Using seed 39392\n",
      "2019-05-13 11:18:20,052 Running with CPU support: 1 threads\n",
      "2019-05-13 11:18:20,339 Reading Frames\n",
      "2019-05-13 11:18:29,460 Highpass Filtering\n",
      "2019-05-13 11:18:29,467 Converting to float64\n",
      "2019-05-13 11:18:29,468 Resampling data\n",
      "2019-05-13 11:18:29,493 Highpass Filtering\n",
      "2019-05-13 11:18:29,498 Remove Padding\n",
      "2019-05-13 11:18:29,499 Reading Frames\n",
      "2019-05-13 11:18:38,979 Highpass Filtering\n",
      "2019-05-13 11:18:38,985 Converting to float64\n",
      "2019-05-13 11:18:38,986 Resampling data\n",
      "2019-05-13 11:18:38,999 Highpass Filtering\n",
      "2019-05-13 11:18:39,003 Remove Padding\n",
      "2019-05-13 11:18:39,003 Will generate a different time series for PSD estimation\n",
      "2019-05-13 11:18:39,004 Reading Frames\n",
      "2019-05-13 11:18:47,856 Highpass Filtering\n",
      "2019-05-13 11:18:48,076 Converting to float64\n",
      "2019-05-13 11:18:48,086 Resampling data\n",
      "2019-05-13 11:18:48,891 Highpass Filtering\n",
      "2019-05-13 11:18:49,009 Remove Padding\n",
      "2019-05-13 11:18:49,010 Reading Frames\n",
      "2019-05-13 11:18:58,344 Highpass Filtering\n",
      "2019-05-13 11:18:58,547 Converting to float64\n",
      "2019-05-13 11:18:58,558 Resampling data\n",
      "2019-05-13 11:18:59,365 Highpass Filtering\n",
      "2019-05-13 11:18:59,478 Remove Padding\n",
      "2019-05-13 11:18:59,478 Applying gates to PSD data\n",
      "2019-05-13 11:19:00,113 Reading configuration file\n",
      "2019-05-13 11:19:00,117 Setting up model\n",
      "2019-05-13 11:19:00,117 Setting up priors for each parameter\n",
      "2019-05-13 11:19:00,122 Sampling in q, mchirp in place of mass1, mass2\n",
      "2019-05-13 11:19:00,122 Loading waveform transforms\n",
      "2019-05-13 11:19:01,339 Setting up sampler\n",
      "2019-05-13 11:19:01,375 Setting max samples per chain to 1000\n",
      "2019-05-13 11:19:01,377 Looking for checkpoint file\n",
      "2019-05-13 11:19:01,433 Initial positions taken from last iteration in bbh_results.hdf.checkpoint\n",
      "2019-05-13 11:19:01,496 Running sampler for 8 to 12 iterations\n",
      "2019-05-13 11:20:00,541 Writing samples to bbh_results.hdf.checkpoint with thin interval 1\n",
      "2019-05-13 11:20:00,609 Writing samples to bbh_results.hdf.bkup with thin interval 1\n",
      "2019-05-13 11:20:00,679 Updating burn in\n",
      "2019-05-13 11:20:00,776 Is burned in: False\n",
      "2019-05-13 11:20:00,776 Computing acls\n",
      "2019-05-13 11:20:00,941 ACT: inf\n",
      "2019-05-13 11:20:00,991 Validating checkpoint and backup files\n",
      "2019-05-13 11:20:01,090 Clearing samples from memory\n",
      "2019-05-13 11:20:01,091 Calculating log evidence\n",
      "2019-05-13 11:20:01,097 log Z, dlog Z: -497509.499044, 11.2280422072\n",
      "2019-05-13 11:20:01,100 Moving checkpoint to output\n",
      "2019-05-13 11:20:01,100 Deleting backup file\n",
      "2019-05-13 11:20:01,101 Done\n"
     ]
    }
   ],
   "source": [
    "!bash run_bbh_example.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the checkpoint file has been renamed to `bbh_results.hdf`, and the backup file is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf bbh_example.ini\r\n",
      "IntroToPyCBCInference2.ipynb           bbh_results.hdf\r\n",
      "L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf run_bbh_example.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we ran for such a short period of time, the samples in `bbh_results.hdf` will look nothing like the posterior. In the next tutorial, we will take a look at a completed result file which has been run for the full time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
